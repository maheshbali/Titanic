{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "a7eb933d-07c2-4e9e-977f-d82296023593",
        "_execution_state": "idle",
        "_uuid": "6a711171dccfd854e935b60d109fa0d2a80e06e8"
      },
      "cell_type": "markdown",
      "source": "This notebook is an introduction into the world of Xgboost for Classifcation and Regression. Motivated by the Russia Dataset that I worked on, trained on Random Forest, no ensemble and ended up in the 83% mark"
    },
    {
      "metadata": {
        "_cell_guid": "12688f47-9564-4ee2-9bba-97069e60a308",
        "_execution_state": "idle",
        "_uuid": "afddcea42e8847ee1ed6e0da0687aec20f03749c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\n\n# Input data files are available in the \"../input/\" directory.b\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4707e84f-5895-4b1d-806a-b5ae4641e3d3",
        "_execution_state": "idle",
        "_uuid": "a8adc4b606c9f5e3cb7f700323b46d3f60603f69",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#load Dataset\ndata = pd.read_csv('../input/diabetes.csv')\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "50e7dccd-d901-4e05-bf62-1ff7b8d4e18a",
        "_execution_state": "idle",
        "_uuid": "a25872189c0f245a213e5c69cc3a3550957c3b46",
        "trusted": false
      },
      "cell_type": "code",
      "source": "data_full = data.copy()\nX_data = data_full.drop('Outcome', axis=1)\ny = data_full.Outcome",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "99b0a828-66a6-4cdb-9f52-2d328e6616d2",
        "_execution_state": "idle",
        "_uuid": "05e6f455a9ae50ac5b0c111be9c367cf0dba069c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1a524d73-d1dc-4895-a9c7-2b95ca0d9a27",
        "_execution_state": "idle",
        "_uuid": "604995c33731c8eee5d2ac9c8812ba89e89bf4a2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Split the dataset into train and Test\nseed = 7\ntest_size = 0.3\nX_trian, X_test, y_train, y_test = train_test_split(X_data, y, test_size=test_size, random_state=seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a51435a6-12ee-4328-8156-69cb3dfdf852",
        "_execution_state": "idle",
        "_uuid": "dbc95cf7d02268dbdaebd19babc85cf05d8fa5d2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Train the XGboost Model for Classification\nmodel1 = xgb.XGBClassifier()\nmodel2 = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n\ntrain_model1 = model1.fit(X_trian, y_train)\ntrain_model2 = model2.fit(X_trian, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5de86a12-216d-4f31-96fd-43f32ea61570",
        "_execution_state": "idle",
        "_uuid": "fd3df6bd3fec8a7e21df914ac2a9d0b78bb03aa3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred1 = train_model1.predict(X_test)\npred2 = train_model2.predict(X_test)\n\nprint('Model 1 XGboost Report %r' % (classification_report(y_test, pred1)))\nprint('Model 2 XGboost Report %r' % (classification_report(y_test, pred2)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "244804f4-74ad-403d-bc79-ca1c56c37a2b",
        "_execution_state": "idle",
        "_uuid": "810f7dfc5fcfcbb642d41158a2e2c14e51b84957",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Let's use accuracy score\nfrom sklearn.metrics import accuracy_score\n\nprint(\"Accuracy for model 1: %.2f\" % (accuracy_score(y_test, pred1) * 100))\nprint(\"Accuracy for model 2: %.2f\" % (accuracy_score(y_test, pred2) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "749d0718-24c8-48e6-9f88-fe89dccf5b73",
        "_execution_state": "idle",
        "_uuid": "5c29773a1fc8ea1aeb34c20fd345d4d2d73e7a14"
      },
      "cell_type": "markdown",
      "source": "Clearly Model 1 performed much better than when we had an estimator"
    },
    {
      "metadata": {
        "_cell_guid": "1c308da1-ab6f-48a4-b875-2f9778e8a77a",
        "_execution_state": "idle",
        "_uuid": "20290ed9c0b7180dab6981c7d3d78f3b972b4e48"
      },
      "cell_type": "markdown",
      "source": "### Let's see what's in Hyperparameter Tunning of XGboost\nBased on the work of [Aarshay Jain](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
    },
    {
      "metadata": {
        "_cell_guid": "50f2fecf-e8fe-463c-b362-ae0113379369",
        "_execution_state": "idle",
        "_uuid": "98b5d26570f023459eb6c2f513dc6b9bebc7af31",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Let's do a little Gridsearch, Hyperparameter Tunning\nmodel3 = xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "876d36a2-182c-49ae-82e9-530f2a38ea21",
        "_execution_state": "idle",
        "_uuid": "e41b73e90de70e0c32934cab8e732eee45d7c909",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_model3 = model3.fit(X_trian, y_train)\npred3 = train_model3.predict(X_test)\nprint(\"Accuracy for model 3: %.2f\" % (accuracy_score(y_test, pred3) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "27801166-41bd-48c3-9c41-047b1c26cf32",
        "_execution_state": "idle",
        "_uuid": "16f03324bd997483c5f1591fb23981e1a04939ac",
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nparam_test = {\n 'max_depth':[4,5,6],\n 'min_child_weight':[4,5,6]\n}\ngsearch = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model4 = gsearch.fit(X_trian, y_train)\npred4 = train_model4.predict(X_test)\nprint(\"Accuracy for model 4: %.2f\" % (accuracy_score(y_test, pred4) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9abca6c3-c32e-4566-81f6-cc328ffd33e6",
        "_execution_state": "idle",
        "_uuid": "ad24b9d56c94580162f9f8356fc1475ae0ce2080",
        "trusted": false
      },
      "cell_type": "code",
      "source": "param_test2b = {\n 'min_child_weight':[6,8,10,12]\n}\ngsearch2b = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model5 = gsearch2b.fit(X_trian, y_train)\npred5 = train_model5.predict(X_test)\nprint(\"Accuracy for model 5: %.2f\" % (accuracy_score(y_test, pred5) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6ae56e43-6aec-414b-ab8c-f4442974b355",
        "_execution_state": "idle",
        "_uuid": "df26443e883a4c4231817338a03935d719829596",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Tune Gamma\nparam_test3 = {\n 'gamma':[i/10.0 for i in range(0,5)]\n}\ngsearch3 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\ntrain_model6 = gsearch3.fit(X_trian, y_train)\npred6 = train_model6.predict(X_test)\nprint(\"Accuracy for model 6: %.2f\" % (accuracy_score(y_test, pred6) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "12b773df-4f8f-489d-8861-5b2e86fa54b4",
        "_execution_state": "idle",
        "_uuid": "5ee38fc72587d38d4740c8be1e953772f046d3cf",
        "trusted": false
      },
      "cell_type": "code",
      "source": "xgb2 = xgb.XGBClassifier(\n learning_rate =0.7,\n n_estimators=1000,\n max_depth=4,\n min_child_weight=6,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\n\ntrain_model7 = xgb2.fit(X_trian, y_train)\npred7 = train_model7.predict(X_test)\nprint(\"Accuracy for model 7: %.2f\" % (accuracy_score(y_test, pred7) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ce36e759-1569-4801-95c9-b992c29f0352",
        "_execution_state": "idle",
        "_uuid": "b7bef0dffba9be3937b23dd7d42ca03a52d2f23a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Let's train a fast RandomForest on the dataset\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nrfc_model = rfc.fit(X_trian, y_train)\npred8 = rfc_model.predict(X_test)\nprint(\"Accuracy for Random Forest Model: %.2f\" % (accuracy_score(y_test, pred8) * 100))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c097a5a0-3f7f-445a-869f-64ac3d9b9700",
        "_execution_state": "idle",
        "_uuid": "564e1309c51e1ccaa2972b1d08c1ceed11bc8666"
      },
      "cell_type": "markdown",
      "source": "**Naive XGBoost Perform well than RandomForest**"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}